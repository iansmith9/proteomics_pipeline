\documentclass{article}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{minted}

\title{Proteomics Pipeline Documentation: proteomics_pipeline}
\author{Documentation Generated by Ian Smith}
\date{\today}

\begin{document}

\maketitle

\section{Overview}
This codebase implements a proteomics data analysis pipeline with support for both Label-Free Quantification (LFQ) and Tandem Mass Tag (TMT) MS2/MS3 workflows. The pipeline handles raw mass spectrometry data processing, database searching, and quantification.

\section{Dependencies}

\subsection{Python Package Dependencies}
\begin{itemize}
    \item sys
    \item pathlib
    \item logging
    \item datetime
    \item typing
    \item functools
    \item pandas
    \item numpy 
    \item tqdm
    \item click
    \item ppx
    \item shutil
    \item mokapot
    \item importlib
    \item pyteomics
    \item statistics
\end{itemize}

\subsection{External Software Dependencies}
\begin{itemize}
    \item Comet Search Engine - will require path
    \item MSConvert (ProteoWizard) - will require path
\end{itemize}

\section{Key Components}

\subsection{Main Pipeline Functions}
\begin{itemize}
    \item Raw file extraction from PRIDE or internal repositories
    \item Conversion of instrument vendor raw files to mzML format
    \item Database searching using Comet with some standard parameter defaults and custom params options
    \item MS1 feature detection using Biosaur2 (for LFQ)
    \item TMT reporter ion quantification (for TMT) for MS2/MS3
    \item FDR control using Mokapot with a joint model and result processing and quantification append.
\end{itemize}

\section{Example Usage}

The pipeline can be run either through command line interface or Python scripts. Recommend running in Jupyter Notebook. Example jupyter notebook accessed in package. This pipeline enables AWS (s3) and dockerized msconvert functionality (please use help command to find arguments in cli functions to enable AWS-based functionality).Below is an example workflow using Python:

\subsection{1a. List Files from PRIDE Repository}
\begin{minted}{python}
from proteomics_pipeline.main import pride_repo_file_display

file_list = pride_repo_file_display(
    path = "C:/project_path_name/",
    pride_repo = "PXD038358",
    file_extension = "*.raw"
)
\end{minted}

\subsection{1b. List Files from Internal Repository}
\begin{minted}{python}
from proteomics_pipeline.main import internal_repo_file_display

local_files = internal_repo_file_display(
    path = "C:/project_path_name/",  
    interal_repo_path = "C:/path_repo_location_raw_files/",
    file_extension = "*.raw"
)
\end{minted}

\subsection{2. Extract Raw Files}
You can extract files from either PRIDE or internal repository:

\subsubsection{From PRIDE:}
\begin{minted}{python}
from proteomics_pipeline.main import raw_file_extract

raw_file_extract(
    path = "C:/project_path_name/",
    pride_or_internal = "pride",
    pride_repo = "PXD038358",
    file_list = ['APEX-GABARAPL2_1.raw', 
                 'APEX-GABARAPL2_2.raw',
                 'APEX-GABARAPL2_3.raw']
)
\end{minted}

\subsubsection{From Internal Repository:}
\begin{minted}{python}
raw_file_extract(
    path = "C:/project_path_name/",
    pride_or_internal = "internal",
    interal_repo_path = "C:/path_repo_location_raw_files/",
    file_extension = "*.raw"
)
\end{minted}

\subsection{3. Convert RAW to mzML}
\begin{minted}{python}
from proteomics_pipeline.main import raw_to_mzml

raw_to_mzml(
    path = "C:/project_path_name/",
    path_msconvert = "C:/Users/local_path_to_msconvert/ProteoWizard/msconvert.exe"
)
\end{minted}

\subsection{4a. Database Search with default params}
\begin{minted}{python}
from proteomics_pipeline.main import db_search

db_search(
    path = "C:/project_path_name/",
    path_comet = "C:/path_to_comet_exe/Comet/comet.win64.exe",
    param_default = "human_tmt11_tryptic_itms2",
    species = "human"
)
\end{minted}

\subsection{4b. Database Search with custom params}
\begin{minted}{python}
from proteomics_pipeline.main import db_search

db_search(
    path = "C:/project_path_name/",
    path_comet = "C:/path_to_comet_exe/Comet/comet.win64.exe",
    params = "C:/path_to_custom_params"
    ## ensure custom params and corresponding fasta are in path of path argument and are the only onces present in the folder
)
\end{minted}

\subsection{5a. For LFQ: MS1 Feature Detection}
\begin{minted}{python}
from proteomics_pipeline.main import detect_ms1_features

detect_ms1_features(
    path = "C:/project_path_namet/"
)
\end{minted}

\subsection{5b. For TMT: Reporter Ion Quantification}
\begin{minted}{python}
from proteomics_pipeline.main import tmt_quant_function

tmt_quant_function(
    path = "C:/project_path_name/",
    da_tol = 0.003
)
\end{minted}

\subsection{6. FDR Control and Result Processing}
\begin{minted}{python}
from proteomics_pipeline.main import train_fdr_model

results = train_fdr_model(
    path = "C:/project_path_name/",
    fasta = None,  # Will use fasta file in path
    lfq_tmt = 'tmt',
    psm_fdr = 0.01,
    peptide_fdr = 0.01,
    protein_fdr = 0.01
)
\end{minted}

\section{Command Line Interface}
The pipeline provides several CLI commands:
\begin{verbatim}
pride_repo_file_display    # Output list files from PRIDE repository
internal_repo_file_display # Output list files from internal repository
raw_file_extract          # Download/copy instument raw files
raw_to_mzml               # Convert instrument raw to mzML format
db_search                 # Run database search
detect_ms1_features       # Run MS1 feature detection
tmt_quant_function        # Quantify TMT reporter ions
train_fdr_model          # Process results with FDR control
\end{verbatim}

\section{Input Requirements}
\begin{itemize}
    \item Raw mass spectrometry files (.raw)
    \item FASTA database file for searches
    \item Comet parameter file (or use built-in defaults)
    \item Project directory structure
\end{itemize}

\section{Output Files}
The pipeline generates:
\begin{itemize}
    \item Processed mzML files in \texttt{/mzml}
    \item Database search results (.pin files)
    \item Feature quantification tables:
    \begin{itemize}
        \item LFQ: \texttt{.features.tsv} files in \texttt{/ms1\_features}
        \item TMT: \texttt{\_ms[2/3]\_quant.csv} files in \texttt{/ms[2/3]\_features}
    \end{itemize}
    \item FDR-controlled results:
    \begin{itemize}
        \item Combined results file with specified FDR thresholds
        \item Mokapot model file (\texttt{svc.model})
    \end{itemize}
    \item Log files for each processing step
\end{itemize}

\section{Function Documentation}
Each function's documentation can be accessed using Python's help() function:

\begin{verbatim}
help(pride_repo_file_display)
help(internal_repo_file_display)
help(raw_file_extract)
help(raw_to_mzml)
help(db_search)
help(detect_ms1_features)
help(tmt_quant_function)
help(train_fdr_model)
\end{verbatim}

\end{document}